{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989237e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403ddc59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='data',train=True,transform=ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901f5b08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(train_data.targets.size())\n",
    "#px.imshow(train_data.data[0], binary_string=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23849ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d (\n",
    "                in_channels=1,\n",
    "                out_channels=8,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2),\n",
    "            nn.SELU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(8,16,5,1,2),\n",
    "            nn.SELU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Linear(16*7*7, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09a8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gradient(neural_net, loader, num_epochs, criterion):\n",
    "    neural_net.train()\n",
    "    running_loss = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i,(inputs,targets) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = neural_net(inputs)\n",
    "            loss = criterion(outputs,targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i%1000 == 0 and i != 0:\n",
    "                print(f'Epoch : {epoch}, i : {i}, loss : {running_loss/1000:.3f}')\n",
    "                running_loss = 0\n",
    "    print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65dcc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ro(neural_net, loader, num_epochs, criterion, std=0.01):\n",
    "    with torch.no_grad():\n",
    "        neural_net.train()\n",
    "        running_loss = 0\n",
    "        best_loss_found = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            for i,(inputs,targets) in enumerate(loader):\n",
    "                \n",
    "                neural_net_cand = NeuralNet()\n",
    "                neural_net_cand.load_state_dict(neural_net.state_dict())\n",
    "                \n",
    "                neural_net_cand.conv1[0].weight += torch.normal(mean=0,std=std,size=neural_net.conv1[0].weight.size())\n",
    "                neural_net_cand.conv2[0].weight += torch.normal(mean=0,std=std,size=neural_net.conv2[0].weight.size())\n",
    "                neural_net_cand.fc.weight += torch.normal(mean=0,std=std,size=neural_net.fc.weight.size())\n",
    "               \n",
    "                outputs = neural_net_cand(inputs)\n",
    "                loss = criterion(outputs,targets)\n",
    "\n",
    "                if loss < best_loss_found:\n",
    "                    best_loss_found = loss\n",
    "                    neural_net = neural_net_cand\n",
    "\n",
    "                    print(f'Epoch : {epoch}, i : {i}, loss : {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5715bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_on_dataset(neural_net, data, criterion):\n",
    "    with torch.no_grad():\n",
    "        loader = DataLoader(data, batch_size=60000, shuffle=True)\n",
    "        for inputs,targets in loader:\n",
    "            outputs = neural_net(inputs)\n",
    "            loss = criterion(outputs,targets)\n",
    "            return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48392bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, i : 1000, loss : 0.223\n",
      "Epoch : 1, i : 1000, loss : 0.090\n",
      "Epoch : 2, i : 1000, loss : 0.066\n",
      "Epoch : 3, i : 1000, loss : 0.057\n",
      "Epoch : 4, i : 1000, loss : 0.046\n",
      "Epoch : 5, i : 1000, loss : 0.043\n",
      "Epoch : 6, i : 1000, loss : 0.038\n",
      "Epoch : 7, i : 1000, loss : 0.032\n",
      "Epoch : 8, i : 1000, loss : 0.029\n",
      "Epoch : 9, i : 1000, loss : 0.027\n",
      "Finished training\n",
      "Loss on whole dataset after training on it :  0.018838059157133102\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neural_net = NeuralNet()\n",
    "optimizer = optim.SGD(neural_net.parameters(), lr=0.01, momentum=0.9)\n",
    "loader = DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_gradient(neural_net, loader, num_epochs, criterion)\n",
    "print('Loss on whole dataset after training on it : ', loss_on_dataset(neural_net, train_data, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfb0c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, i : 0, loss : 2.298\n",
      "Epoch : 3, i : 0, loss : 2.295\n",
      "Epoch : 13, i : 0, loss : 2.292\n",
      "Epoch : 14, i : 0, loss : 2.290\n",
      "Epoch : 16, i : 0, loss : 2.288\n",
      "Loss on whole dataset after training on it :  2.3043665885925293\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neural_net = NeuralNet()\n",
    "loader = DataLoader(train_data, batch_size=60000, shuffle=True)\n",
    "num_epochs = 18\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_ro(neural_net, loader, num_epochs, criterion, std=0.01)\n",
    "print('Loss on whole dataset after training on it : ', loss_on_dataset(neural_net, train_data, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8c90861b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, i : 0, loss : 3.183\n",
      "Epoch : 0, i : 514, loss : 3.141\n",
      "Loss on whole dataset after training on it :  2.3157432079315186\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neural_net = NeuralNet()\n",
    "loader = DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_ro(neural_net, loader, num_epochs, criterion, std=0.1)\n",
    "print('Loss on whole dataset after training on it : ', loss_on_dataset(neural_net, train_data, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc344610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, i : 0, loss : 2.388\n",
      "Epoch : 0, i : 7, loss : 2.388\n",
      "Epoch : 0, i : 20, loss : 2.360\n",
      "Epoch : 0, i : 37, loss : 2.275\n",
      "Epoch : 0, i : 91, loss : 2.084\n",
      "Epoch : 3, i : 123, loss : 2.068\n"
     ]
    }
   ],
   "source": [
    "neural_net = NeuralNet()\n",
    "loader = DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_zero_order(neural_net, loader, num_epochs, criterion, std=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b656f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "neural_net = NeuralNet()\n",
    "loader = DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_ro(neural_net, loader, num_epochs, criterion, std=1)\n",
    "print('Loss on whole dataset after training on it : ', loss_on_dataset(neural_net, train_data, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1852b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASSRS:\n",
    "    def __init__(self, func, nb_dim, step, a, i2_limit, step_decrease, i1_freq, step_increase):\n",
    "        self.func = func\n",
    "        self.nb_dim = nb_dim\n",
    "        self.step = step\n",
    "        self.a = a\n",
    "        self.i2_limit = i2_limit\n",
    "        self.step_decrease = step_decrease\n",
    "        self.i1_freq = i1_freq\n",
    "        self.step_increase = step_increase\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.i1 = 0\n",
    "        self.i2 = 0\n",
    "        self.x = np.zeros(self.nb_dim)\n",
    "        self.f_x = np.inf\n",
    "        \n",
    "    def random_point_hypersphere(self, step):\n",
    "        x = np.random.normal(0, step, size=(self.nb_dim,))\n",
    "        step = np.linalg.norm(x)\n",
    "        return x / step\n",
    "    \n",
    "    def compare_step_sizes(self, step_1, step_2):\n",
    "        x_1 = self.x + self.random_point_hypersphere(step_1,)\n",
    "        x_2 = self.x + self.random_point_hypersphere(step_2)\n",
    "        f_1 = self.func(x_1)\n",
    "        f_2 = self.func(x_2)\n",
    "        print(f_1)\n",
    "        print(f_2)\n",
    "        return (x_1,f_1,step_1) if f_1 < f_2 else (x_2,f_2,step_2)\n",
    "    \n",
    "    def iterate(self, verbose=False):\n",
    "        print(self.step)\n",
    "        # 1 Step size of nominal step size\n",
    "        # 1 Step size of large step size\n",
    "        if self.i1%self.i1_freq==0 and self.i1!=0:\n",
    "            x_cand,f_cand,step_cand = self.compare_step_sizes(self.step, self.step+self.step_increase)\n",
    "            if f_cand < self.f_x:\n",
    "                self.x,self.f_x,self.step = x_cand,f_cand,step_cand\n",
    "            if verbose:\n",
    "                print(f'Size step : {self.step}, loss : {self.f_x}')\n",
    "        \n",
    "        larger_step = self.step*(1+self.a)\n",
    "        x_cand,f_cand,step_cand = self.compare_step_sizes(self.step, larger_step)\n",
    "        \n",
    "        if f_cand < self.f_x:\n",
    "            # One step produced an improvement\n",
    "            self.x,self.f_x,self.step = x_cand, f_cand,step_cand\n",
    "            self.i2 = 0\n",
    "            if verbose:\n",
    "                print(f'Size step : {self.step}, loss : {self.f_x}')\n",
    "        else:\n",
    "            # No steps produced an improvement\n",
    "            self.i2 = self.i2 + 1\n",
    "            if self.i2 == self.i2_limit:\n",
    "                # No improvement for a long time, reduce step size\n",
    "                self.step *= 1-self.step_decrease\n",
    "                self.i2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb9c766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9e4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Holder:\n",
    "    def __init__(self, cnn):\n",
    "        self.cnn = cnn\n",
    "        self.weights_1_size = torch.prod(torch.tensor(cnn.conv1[0].weight.shape))\n",
    "        self.weights_2_size = torch.prod(torch.tensor(cnn.conv2[0].weight.shape))\n",
    "        self.weights_3_size = torch.prod(torch.tensor(cnn.fc.weight.shape))\n",
    "        self.weights_size = self.weights_1_size + self.weights_2_size + self.weights_3_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90794be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first argument : parameters of the NN, that ASSRS will try to fine tune\n",
    "# second : targets, given at the beginning of each epoch (ASSRS does not see it)\n",
    "def loss_func(x, cnn_h, inputs, targets):\n",
    "    # convert x to weights\n",
    "    cnn_h.cnn.conv1[0].weights = x[:cnn_h.weights_1_size]\n",
    "    cnn_h.cnn.conv2[0].weights = x[cnn_h.weights_1_size:cnn_h.weights_2_size]\n",
    "    cnn_h.cnn.fc.weights = x[cnn_h.weights_2_size:]\n",
    "    print(cnn_h.cnn(inputs).shape)\n",
    "    print(targets.shape)\n",
    "    loss = nn.CrossEntropyLoss(cnn_h.cnn(inputs),targets)\n",
    "    print(loss)\n",
    "    return loss\n",
    "\n",
    "def train_assrs(cnn, loader, num_epochs=10):\n",
    "    with torch.no_grad():\n",
    "        cnn_h = CNN_Holder(cnn)\n",
    "        assrs = ASSRS(func=lambda x:print(x),\n",
    "                      nb_dim=cnn_h.weights_size,\n",
    "                      step=0.1,\n",
    "                      a=0.01,\n",
    "                      i2_limit=10,\n",
    "                      step_decrease=0.01,\n",
    "                      i1_freq=10,\n",
    "                      step_increase=0.01)\n",
    "        cnn.train()\n",
    "        running_loss = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            for i1,(inputs,targets) in enumerate(loader):\n",
    "                \n",
    "                assrs.func = lambda x: loss_func(x,cnn_h,inputs,targets)\n",
    "                assrs.iterate()\n",
    "\n",
    "                print(f'Epoch : {epoch}, i : {i}, loss : {assrs.f_x:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8b22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "torch.Size([5000, 10])\n",
      "torch.Size([5000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13488/2006277881.py\u001b[0m in \u001b[0;36mtrain_assrs\u001b[1;34m(cnn, loader, num_epochs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0massrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcnn_h\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0massrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch : {epoch}, i : {i}, loss : {assrs.f_x:.3f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13488/1506577953.py\u001b[0m in \u001b[0;36miterate\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mlarger_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mx_cand\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf_cand\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep_cand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompare_step_sizes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlarger_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf_cand\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_x\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13488/1506577953.py\u001b[0m in \u001b[0;36mcompare_step_sizes\u001b[1;34m(self, step_1, step_2)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mx_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_point_hypersphere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mx_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_point_hypersphere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mf_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mf_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13488/2006277881.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0massrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcnn_h\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0massrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13488/2006277881.py\u001b[0m in \u001b[0;36mloss_func\u001b[1;34m(x, cnn_h, inputs, targets)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_h\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_h\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m     def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n\u001b[0;32m   1157\u001b[0m                  reduce=None, reduction: str = 'mean', label_smoothing: float = 0.0) -> None:\n\u001b[1;32m-> 1158\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_smoothing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_WeightedLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_WeightedLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py\u001b[0m in \u001b[0;36mlegacy_get_string\u001b[1;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnn = NeuralNet()\n",
    "loader = DataLoader(train_data, batch_size=5000, shuffle=True)\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_assrs(cnn, loader, num_epochs)\n",
    "print('Loss on whole dataset after training on it : ', loss_on_dataset(cnn, train_data, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7758cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self,att):\n",
    "        self.att=att\n",
    "    def oui():\n",
    "        print(self.att)\n",
    "\n",
    "def g(f):\n",
    "    f()\n",
    "\n",
    "a = A(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2775c058",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "oui() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22856/2896612591.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moui\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: oui() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "a.oui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f5738ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "a[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7af0d749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 5\n",
    "b = lambda x: x+a\n",
    "b(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f2ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
